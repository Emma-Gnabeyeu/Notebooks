{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP556, Ecole Polytechnique, 2022-23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 5 - Régression empirique pour l'approximation d'espérance conditionnelle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1.  Un exemple de programmation dynamique pour un problème d'arrêt optimal\n",
    "\n",
    "On considère le processus stochastique à deux pas \n",
    "\n",
    "$$X_i = x_0 \\ e^{-\\frac12 \\sigma^2 T_i \\ + \\ \\sigma \\, W_{i}}, \\quad\n",
    "\\qquad i=0,1,2,\n",
    "$$\n",
    "\n",
    "où $x_0$ et $\\sigma$ sont deux paramètres positifs, $T_i=i$, et $(W_i)_{0\\le i \\le 2}$ est un processus à temps discret définit comme suit: $W_0 = 0$, et \n",
    "\n",
    "- la v.a.  $W_{1}$ suit une loi Gaussienne $\\mathcal{N}(0,T_1)$,\n",
    "\n",
    "\n",
    "- $W_{2} = W_{1} + \\Delta W$, où $\\Delta W$ est une v.a. de loi $\\mathcal{N}(0,T_2 - T_1)$ indépendante de $W_{1}$.\n",
    "\n",
    "\n",
    "__Pour la terminologie__: \n",
    "\n",
    " - $(W_i)_{0\\le i \\le 2}$ est la version en temps discret de ce que l'on appelle un _mouvement Brownien_, un processus défini en temps continu.\n",
    " \n",
    "   En particulier, c'est une chaîne de Markov par rapport à sa filtration $(\\mathcal{F}_0, \\mathcal{F}_1, \\mathcal{F}_2)$, où $\\mathcal{F}_i = \\sigma(W_0, \\dots, W_i)$.\n",
    "\n",
    "\n",
    " - Le processus $(X_i)_{0\\le i \\le 2}$ est appelé _mouvement Brownien géometrique_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Le problème d'arrêt optimal__\n",
    "\n",
    "Dans la suite, on voit le processus $X$ comme modèle aléatoire pour la valeur d'un actif sur un marché (par exemple, une action).\n",
    "\n",
    "C'est un modèle à temps discret sur deux périodes ($[T_0, T_1]$ et $[T_1, T_2]$), très simplifié donc, mais la nature du problème et la méthode de calcul présentée ci-dessous restent les mêmes si on passe à un système à $n$ dates $T_1,\\dots, T_n$.\n",
    "\n",
    "$\\blacktriangleright$ Le contrat financier _option Put Bermuda_ est un exemple de jeu à arrêt optimal entre deux parties (l'acheteur et le vendeur du contrat): l'acheteur du Put Bermuda paye au vendeur un prix $u_0$ à l'instant $T_0$, et gagne en échange le droit de recevoir le montant $(K-X_t)^+ = \\max(K-X_t, 0)$ à une date $t\\in\\{0,1,2 \\}$ de son choix.\n",
    "\n",
    "La constante $K > 0$ est fixée dès le départ (alors que la date d'exercice $t$ du contrat ne l'est pas: elle est arrêtée par l'acheteur pendant la vie du produit).\n",
    "\n",
    "$\\blacktriangleright$ On peut justifier que le juste prix à attribuer à ce produit financier à la date $T_0$ est donné par\n",
    "\n",
    "$$\n",
    "u_0 = \\sup_{\\tau \\, \\in \\, \\mathcal{T}_2 } {\\mathbb E} \\left[ (K - X_\\tau)^+ \\right],\n",
    "$$\n",
    "\n",
    "où $\\mathcal{T}_2$ est l'ensemble de temps d'arrêt à valeurs dans $\\{0,T_1,T_2\\}$ par rapport à la filtration $(\\mathcal{F}_i)_{0\\le i \\le 2}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__La transformation en équation dynamique rétrograde__\n",
    "\n",
    "On souhaite évaluer $u_0$ par une méthode Monte-Carlo. \n",
    "\n",
    "On remarquera que la définition de $u_0$ contient un $\\sup$ sur un ensemble infini de fonctions (l'ensemble $\\mathcal{T}_2$ de temps d'arrêt).\n",
    "\n",
    "Une manière de simplifier le calcul est de faire appel à la formulation dynamique du problème: en posant \n",
    "\n",
    "$$\n",
    "Y_i = \\mbox{ess}\\sup_{\\tau \\,  \\in \\,  \\mathcal{T}_2: \\, \\tau \\, \\ge \\, i}\n",
    "{\\mathbb E} \\left[ (K - X_\\tau)^+|\\mathcal F_{i} \\right],\n",
    "$$\n",
    "\n",
    "de telle manière que\n",
    "$$\n",
    "Y_0 = u_0,\n",
    "$$\n",
    "\n",
    "on peut montrer que le processus $(Y_i)_{0 \\le i \\le 2}$ obéit à l'équation rétrograde\n",
    "\n",
    "$$\n",
    "\\left \\{\n",
    "\\begin{aligned}\n",
    "&Y_2 = (K-X_2)^+\n",
    "\\\\\n",
    "&Y_i = \\max \\left( (K-X_i)^+, \\, {\\mathbb E} \\left[Y_{i+1}|\\mathcal{F}_i\\right] \\right)\n",
    "\\qquad i = 0, 1.\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "qui est l'_équation de programmation dynamique_ pour le problème d'arrêt optimal $u_0$. C'est cette équation que nous allons approcher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Question préliminaire: \n",
    "Montrer que $Y_i$ est de la forme $Y_i= u_i (W_i)$ pour une fonction mesurable $u_i: \\mathbb{R} \\to \\mathbb{R}$.\n",
    "Remarquer que le prix de l'option Bermuda en $t=0$ s'écrit comme l'espérance emboitée suivante\n",
    "\n",
    "$$\n",
    "u_0 = Y_0\n",
    "= \\max \\left\\{ (K-x_0)^+, {\\mathbb E} \\left[ \\max\\left( (K - X_1)^+, v_1(W_1) \\right) \\right] \\right\\},\n",
    "$$\n",
    "\n",
    "où $v_1(W_1) = {\\mathbb E}\\left[(K-X_2)^+|W_1 \\right]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ On note $(W_1^m,W_2^m)_{1 \\le m \\le M}$ un échantillon de tirages i.i.d. du couple $(W_1,W_2)$, et on pose $X_i^m = x_0 \\, e^{-\\frac12 \\sigma^2 T_i \\, + \\, \\sigma \\, W_i^m}$ pour tout $m$.\n",
    "\n",
    "\n",
    "1. __Valeur de référence (_benchmark_) du prix: on utilise l'expression explicite de la fonction $v_1$.__ Dans cette question, on utilisera la formule\n",
    "\t\n",
    "    $$\n",
    "  v_1(w) = {\\mathbb E}\\left[(K-X_2)^+|W_1 = w \\right] = \n",
    "  K \\, N(-d_2) - x \\, N(-d_1)\n",
    "\t$$\n",
    "    où\n",
    "\t$$\n",
    "\tx = x_0  \\, e^{-\\frac12 \\sigma^2 T_1 + \\sigma \\, w},\n",
    "\t\\qquad d_2 = \\frac{\\log(x/K)}{\\sigma \\sqrt{T_2-T_1}} - \\frac12 \\sigma \\sqrt{T_2-T_1},\n",
    "\t\\qquad d_1 = d_2 + \\sigma \\sqrt{T_2-T_1},\n",
    "\t$$\n",
    "    \n",
    "\toù $N(z) = \\int_{-\\infty}^z e^{-y^2/2} \\frac{dy}{\\sqrt{2 \\pi}}$ est la fonction de répartition gaussienne, accessible en Python via la fonction `scipy.stats.norm.cdf`.\n",
    "    \n",
    "    (Remarque: Dans la terminologie financière, la fonction $\\mathrm{v_1}$ est le prix d'une option Put (non Bermuda, mais *Européenne*) dans le modèle de Black-Scholes.)\n",
    "    \n",
    "    __1 (a)__. Coder la formule ci-dessus pour la fonction $v_1$. Vérifier que pour les paramètres $x_0=1$, $T_1=1$, $T_2=2 $, $K=1.2$, $\\sigma=0.2$, on obtient bien $v_1(0) \\approx 0.2374$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from time import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parametres\n",
    "K = 1.2\n",
    "x0 = 1.\n",
    "sigma = 0.2\n",
    " \n",
    "T2 = 2.\n",
    "T1 = T2 / 2.\n",
    " \n",
    "M = int(5e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23742104895721394\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "## Q1 (a): formule explicite\n",
    "##         pour l'esperance conditionnelle \n",
    "###################################################\n",
    " \n",
    "def fonction_v_1(x0, T1, T2, K, W1, sigma):\n",
    "    \"\"\"\n",
    "    La fonction v_1(W1) de la question 1.(a)\n",
    "    \n",
    "    Autrement dit: le prix en T1 du Put Black-Scholes de maturite T2\n",
    "    en fonction de la valeur courante du mouv Brownien en T1.\n",
    "    \n",
    "    Paramètres:\n",
    "    W1: un array numpy\n",
    "    \"\"\"\n",
    "    sigmaSqrtDeltaT = sigma * np.sqrt(T2 - T1)\n",
    "     \n",
    "    ######################################\n",
    "    # TO DO: coder la formule explicite\n",
    "    # pour la fonction v_1\n",
    "    ######################################\n",
    "        \n",
    "    d2 = (np.log(x0/K) + sigma*W1 - 0.5*sigma*sigma*T1 ) / sigmaSqrtDeltaT - 0.5*sigmaSqrtDeltaT\n",
    "    d1 = d2 + sigmaSqrtDeltaT\n",
    "    \n",
    "    return  K*norm.cdf(-d2) - x0*np.exp(sigma*W1 - 0.5*sigma*sigma*T1)*norm.cdf(-d1) \n",
    "    ## Output: un array de la meme taille que W\n",
    "    return np.zeros(np.size(W1))\n",
    "\n",
    "\n",
    "print(fonction_v_1(x0, T1, T2, K, 0, sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La connaissance explicite de la fonction $v_1$ permet d'écrire l'estimateur\n",
    "$$\n",
    "u_0^{M} =\n",
    "\\max \\Bigl\\{ (K-x_0)^+, \\frac 1M \\sum_{m = 1}^M u_1(W_{1}^m)\\Bigr\\}\n",
    "$$\n",
    "\n",
    "où $u_1(W_{1}^m) = \\max\\left( (K - X_{1}^m)^+, v_1(W_{1}^m) \\right)$.\n",
    "\n",
    "\n",
    "__1 (c)__ Simuler cet estimateur dans la cellule suivante. Pour calculer le maximum $\\max(a,b)$ entre deux nombres, on pourra utiliser la fonction `numpy.maximum(a,b)`.\n",
    "\n",
    "$\\blacktriangleright$ __TCL pour $u_0^{M}$__. On rappelle que la méthode delta (ou méthode de substitution) affirme que si $\\overline Y_M$ est la moyenne empirique d'une suite $(Y_m)_{m \\ge 1}$ de v.a. i.i.d. de carré intégrable et $f$ une fonction dérivable au point $\\mathbb E[Y]$, l'estimateur $f(\\overline Y_M)$ de $f(\\mathbb E [Y])$ satisfait un TCL:\n",
    "\n",
    "$$ \n",
    "\\frac 1{\\sqrt{M}} \\left( f(\\overline Y_M) - f(\\mathbb E [Y]) \\right)\n",
    "\\to \n",
    "\\mathcal N \\left(0, f'(\\mathbb E [Y])^2 \\mathrm{Var}(Y) \\right).\n",
    "$$\n",
    "\n",
    "Pour les valeurs considérées des paramètres, on peut montrer que l'on a\n",
    "\n",
    "$$\n",
    "{\\mathbb E} \\left[ \\max\\left( (K - X_1)^+, v_1(W_1) \\right) \\right] > (K-x_0)^+.\n",
    "$$\n",
    "\n",
    "L'estimateur $u_0^{M}$ satisfait-il un TCL? Avec quelle variance limite?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prix benchmark = 0.2481 +/- 0.0039 \n",
      "\n",
      "Erreur relative (TCL) = 0.016 \n",
      "\n",
      "Time: 0.0035 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "## On genere les tirages gaussiens et on construit\n",
    "## le mouv Brownien W et le mouv Brownien géometrique\n",
    "## aux instants T1 et T2\n",
    "###################################################\n",
    "def MBG(x0, T, sigma, W):\n",
    "    \"\"\"\n",
    "    Processus X: mouvement Brownien géometrique à\n",
    "    l'instant T, de parametre de volatilite sigma,\n",
    "    a partir de la valeur du mouvement Brownien W\n",
    "    \"\"\"\n",
    "    return x0 * np.exp(-0.5*sigma*sigma*T + sigma * W)\n",
    " \n",
    "time0 = time()\n",
    " \n",
    "#################################################\n",
    "## TO DO: Remplacer W1, W2 avec un echantillon de\n",
    "## tirages du mouvement Brownien aux dates T1 et T2\n",
    "## et X1, X2 avec le MBG correspondant\n",
    "W1 = np.sqrt(T1) * np.random.randn(M) # gaussiennes N(0,T_1)\n",
    "W2 = W1 + np.sqrt(T2-T1) * np.random.randn(M) # W1 + gaussiennes N(0,T_2-T_1) independantes\n",
    "\n",
    "X1 = MBG(x0, T1, sigma, W1)\n",
    "X2 = MBG(x0, T2, sigma, W2)\n",
    "################################################\n",
    " \n",
    "time0_1 = time()\n",
    " \n",
    "timeSimulations = time0_1 - time0\n",
    " \n",
    "###################################################\n",
    "### 1. Prix Benchmark\n",
    "###################################################\n",
    " \n",
    "time1 = time()\n",
    " \n",
    "v_1 = fonction_v_1(x0, T1, T2, K, W1, sigma)\n",
    " \n",
    "################################################\n",
    "## TO DO: completer avec le calcul du prix\n",
    "## benchmark u_0^M et l'estimation de la variance\n",
    "## dans le TCL pour l'estimateur\n",
    "u_1=np.maximum(v_1,np.maximum(K-X1,0))\n",
    "prix_benchmark = np.maximum(np.mean(u_1),np.maximum(K-x0,0))\n",
    "var_TCL = np.var(u_1)\n",
    "################################################\n",
    " \n",
    "rayonIC = 1.96 * np.sqrt(var_TCL/M)\n",
    " \n",
    "time2 = time()\n",
    " \n",
    "print(\"Prix benchmark = %1.4f +/- %1.4f \\n\" %(prix_benchmark, rayonIC) )\n",
    "print(\"Erreur relative (TCL) = %1.3f \\n\" %(rayonIC / prix_benchmark) )\n",
    "print(\"Time: %1.4f \\n\" %(time2 - time1 + timeSimulations) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Prix par régression empirique:__ \n",
    "\n",
    "   En pratique (si le modèle est plus complexe qu'un mouvement Brownien géometrique, ou s'il y a plus que trois dates $T_0, \\dots, T_n$), la fonction à injecter dans l'estimateur Monte-Carlo (ici $v_1$) n'est pas connue explicitement.\n",
    "\n",
    "   Nous allons donc l'estimer, à partir des même tirages $(X_1^m, X_2^m)$, avec une méthode de régression sur un espace d'approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On choisit comme espace d'approximation pour la fonction $v_1$ l'espace engendré par les fonctions indicatrices de $n$ intervalles disjoints:\n",
    "$$\n",
    "\\phi_k = 1_{I_k},\n",
    "\\quad\n",
    "\\mbox{où }\n",
    "I_k = \\left[-a + (k-1) \\frac{2a}n, -a + k \\frac{2a}n \\right[;\n",
    "\\quad a > 0, \n",
    "\\quad k = 1, \\dots, n\n",
    "$$\n",
    "$$\n",
    "\\text{Vect}(\\phi_1,\\dots, \\phi_n)\n",
    "= \\left\\{\\sum_{k=1}^n \\alpha_k \\phi_k(\\cdot): \\alpha_1, \\dots, \\alpha_n \\in \\mathbb{R} \\right\\}.\n",
    "$$\n",
    "  On remarquera que $\\cup_k I_k = [-a, a[$: $a$ est donc un paramètre de troncature (toute fonction d'approximation obtenue sera nulle en dehors de cet intervalle).\n",
    "\n",
    "  On notera $\\alpha \\cdot \\phi(\\cdot) = \\sum_{k=1}^n \\alpha_k \\phi_k(\\cdot)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - L'approximation empirique de la fonction $v_1(\\cdot)$ est donnée par\n",
    "$$\n",
    "\\tilde v_1(\\cdot) = \\sum_{k=1}^{n} \\alpha_k^* \\ 1_{I_k}(\\cdot)\n",
    "$$\n",
    "où\n",
    "$$ \\label{e:regrEmp}\n",
    "\\begin{aligned}\n",
    "\\alpha^* \\in \\underset{\\alpha\\in \\mathbb{R}^n}{\\rm arg\\min}\n",
    "\\ \\sum_{m = 1}^M\n",
    "\\left((K-X_2^m)^+ - \\alpha \\cdot \\phi(W_1^m)\\right)^2.\n",
    "\\end{aligned}\n",
    "$$\n",
    "Si l'argmin n'est pas unique, on choisira le $\\alpha^*$ de norme minimale dans $\\mathbb{R}^n$.\n",
    "\n",
    "L'estimateur par régression empirique du prix du Put Bermuda est maintenant\n",
    "$$\n",
    "\\tilde{u}_0^{M} = \n",
    "\\max \\Bigl\\{\n",
    "(K - x_0)^+, \\frac 1M \\sum_{m=1}^M \\tilde u_1(W_1^m)\n",
    "\\Bigr\\}\n",
    "$$\n",
    "où $\\tilde u_1(W_1^m) =  \\max \\left( (K - X_{1}^m)^+, \\tilde{v}_1(W_1^m) \\right)$.\n",
    "\n",
    "__2 (a) Question théorique__: Donner l'expression des coefficients de régression $\\alpha^*_k$ qui sont solution du problème d'optimisation ci-dessus.\n",
    "\n",
    "__2 (b) suite__: Utiliser l'expression obtenue pour compléter la fonction coeffsRegressionEmpirique dans la cellule ci-dessous. Compléter le calcul de l'estimateur $\\tilde{u}_0^{M}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prix par regression empirique = 0.2511\n",
      "Time: 0.0029 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcc36467040>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################\n",
    "### 2. Prix par regression empirique\n",
    "###################################################\n",
    " \n",
    "##################################\n",
    "### On genere les cellules I_k\n",
    "##################################\n",
    "# Choix de la troncature\n",
    "a = 3.*np.sqrt(T1)\n",
    " \n",
    "## Dimension n  de l'espace d'approximation.\n",
    "## Une règle pratique : prendre n de l'ordre de M^{d / (d+2)}\n",
    "n = int(M**(1./3))\n",
    " \n",
    "intervals = np.linspace(-a, a, n+1)\n",
    " \n",
    "####################################################\n",
    "## TO DO: calculer\n",
    "## - Les coefficients de regression empirique alpha\n",
    "## - Le vecteur v_1_tilde(W1) de taille M\n",
    "##   dans l'array v_1_tilde\n",
    "####################################################\n",
    "def regressionEmpirique(W1, W2, intervals, T2, K, x0, sigma):\n",
    "    step = intervals[1] - intervals[0]\n",
    "    alpha = np.zeros(intervals.size - 1)\n",
    "    \n",
    "    v_1_tilde = np.zeros(M)\n",
    "     \n",
    "    for k in range(intervals.size - 1):\n",
    "        leftPoint = intervals[k]\n",
    "        \n",
    "        # Array de taille M de booléens True/False\n",
    "        insideCell = np.logical_and( leftPoint <= W1, W1 < leftPoint+step )         \n",
    "        \n",
    "        # W2[insideCell]: la valeur W_2[m] est conservée uniquement si insideCell[m] = True\n",
    "        if (np.size(insideCell)>0):\n",
    "            X_T2 = MBG(x0, T2, sigma, W2[insideCell])\n",
    "        \n",
    "        #############################################\n",
    "        ## TO DO: Completer avec le calcul des\n",
    "        ## coefficients alpha[k]\n",
    "        #############################################\n",
    "            alpha[k]=np.mean(np.maximum(K-X_T2,0))\n",
    "        #############################################\n",
    "        ## TO DO: Completer avec le calcul de l'approximation\n",
    "        ## empirique v_1_tilde(W1) (array de taille M)\n",
    "        #############################################\n",
    "        v_1_tilde[insideCell]=alpha[k]\n",
    "     \n",
    "    return alpha, v_1_tilde\n",
    " \n",
    "time3 = time()\n",
    " \n",
    "alpha, v_1_tilde = regressionEmpirique(W1, W2, intervals, T2, K, x0, sigma) \n",
    "\n",
    "################################################\n",
    "## TO DO: Completer avec le calcul du prix\n",
    "## par regression empirique u_tilde_0^M \n",
    "\n",
    "u_1_tilde=np.maximum(v_1_tilde, np.maximum(K-X1,0))\n",
    "prix_RegrEmp = np.maximum(np.maximum(K-x0,0),np.mean(u_1_tilde))\n",
    "################################################\n",
    "time4 = time()\n",
    " \n",
    "print(\"Prix par regression empirique = %1.4f\" %prix_RegrEmp)\n",
    "print(\"Time: %1.4f \\n\" %(time4 - time3 + timeSimulations))\n",
    " \n",
    "######################################\n",
    "## On peut afficher la vraie fonction\n",
    "## v_1 et son approximation empirique\n",
    "## pour comparaison\n",
    "#####################################\n",
    "x = np.linspace(-a, a, 100)\n",
    " \n",
    "v_1_exact = fonction_v_1(x0, T1, T2, K, x, sigma)\n",
    " \n",
    "plt.plot(x, v_1_exact, color=\"b\", label=\"$v_1$\")\n",
    " \n",
    "plt.step(intervals, np.append(alpha, alpha[-1]), where=\"post\", color=\"r\", label=r\"$\\tilde{v}_1$\")\n",
    " \n",
    "plt.xlabel(\"valeurs de $W_1$\", fontsize=17)\n",
    "plt.legend(loc=\"best\", fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Prix par _Simulations dans les simulations_ (ou _Nested Monte-Carlo_)__. L'estimateur de $u_0^M$ est\n",
    "$$\n",
    "\\hat{u}_0^{M} = \\max \\Bigl\\{ (K-x_0)^+,\n",
    "\\frac 1M \\sum_{m = 1}^M \\max\\left( (K - X_{1}^m)^+, \\hat{v}_{1}^m \\right)\n",
    "\\Bigr\\}\n",
    "$$\n",
    "où pour tout $m$, $\\hat{v}_{1}^m$ est obtenue à partir d'un échantillon de $M$ simulations i.i.d.\n",
    "de la loi de $W_2$ conditionellement à $W_1 = x$ calculée en $x = W_1^m$, notées \n",
    "$(W_2^{m,m'})_{1 \\le m' \\le M}$:\n",
    "$$\n",
    "\\hat{v}_{1}^m = \\frac1{M} \\sum_{m' = 1}^M \\bigl(K - x_0 \\, e^{-\\frac12 \\sigma^2 T_2 + \\sigma \\, W_2^{m,m'}} \\bigr)^+.\n",
    "$$\n",
    "    (a) Quelle est la loi de $W_2$ conditionelle à $W_1 = x$? Pour chaque $m$, simuler les $M$ tirages $W_2^{m, m'}$ suivant cette loi conditionnelle en $x =W_1^m$.\n",
    "    \n",
    "    (b) Compléter le calcul de cet estimateur dans le code ci-dessous, et comparer avec les méthodes précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prix Sim dans sim = 0.2482\n",
      "Time: 0.8219 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "#### 3. Prix \"simulations dans les simulations\"\n",
    "###################################################\n",
    " \n",
    "###################################################\n",
    "## On genere M tirages de X2 pour chaque valeur\n",
    "## dans l'echantillon X1.\n",
    "## Il faudra donc repeter les tirages de M gaussiennes iid \n",
    "## POUR CHAQUE valeur de X1.\n",
    "###################################################\n",
    "sum_u_1 = 0.\n",
    " \n",
    "time7 = time()\n",
    " \n",
    "for m, w1 in enumerate(W1):\n",
    "    G = np.random.randn(M)\n",
    "     \n",
    "    ###################################################\n",
    "    ## To Do: completer avec\n",
    "    ## - les tirages de W_2 conditionnellement a W1 = w1\n",
    "    ## - la mise a jour de la somme des contributions à\n",
    "    ##   la variable u_1\n",
    "    W2 = w1 + np.sqrt(T2 - T1) * G\n",
    "    \n",
    "    ## On implemente v_1_hat\n",
    "    v_1_hat = np.mean( np.maximum(K - MBG(x0, T2, sigma, W2),0) )\n",
    "    \n",
    "    max_courant = np.maximum( np.maximum(K - MBG(x0, T1, sigma, w1),0), v_1_hat)\n",
    "    \n",
    "    sum_u_1 += max_courant\n",
    "    ###################################################\n",
    "\n",
    "u_0 = np.maximum( np.maximum(K-x0,0.), sum_u_1/M )\n",
    "    \n",
    "time8 = time()\n",
    " \n",
    "print(\"Prix Sim dans sim = %1.4f\" %u_0)\n",
    "print(\"Time: %1.4f\" %(time8 - time7), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. __Prix Longstaff-Schwartz:__\n",
    "\n",
    "   Enfin, il est aussi possible d'approcher le temps d'arrêt $\\tau^*$ (qui, pour rappel, est une variable aléatoire) qui atteint l'optimum dans le problème originaire, c'est à dire $\\tau^*$ tel que\n",
    "$$\n",
    "{\\mathbb E} \\left[ (K - X_{\\tau^*})^+ \\right] =\n",
    "\\sup_{\\tau \\, \\in \\, \\mathcal{T}_2 } {\\mathbb E} \\left[ (K - X_\\tau)^+ \\right]\n",
    "$$\n",
    "   \n",
    "   Cette approche est appélée méthode de Longstaff-Schwartz en référence à l'article _[F. Longstaff, E. Schwartz, Valuing American Options by Simulation: A Simple Least-Squares Approach. The Review of Financial Studies, 2001]_.\n",
    "   \n",
    "   On peut montrer les propriétés suivantes (qui restent vraies pour le problème à $n$ dates):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ On pose $\\tau^\\star = \\min\\{i\\ge 0 : Y_i = (K - X_i)^+ \\}$ et on note $(Y^\\star_i)_{0\\le i \\le 2}$ le processus arrêté $Y^\\star_i = Y_{i \\wedge \\tau^\\star}$. Montrer que $\\tau^\\star \\in \\mathcal{T}_2$ et que\n",
    "$$\n",
    "Y^\\star_i = \\mathbb{E} \\left[Y^\\star_{i+1} \\big|\\mathcal{F}_i \\right].\n",
    "$$\n",
    "\n",
    "  (_Indication_: écrire $Y_{i \\wedge \\tau^\\star} = 1_{i < \\tau^\\star} Y_i \\, + \\, 1_{i \\ge \\tau^\\star} Y_{\\tau^\\star}$ et observer que sur l'événement $\\{i < \\tau^\\star\\}$, on a $Y_i = \\mathbb{E}[Y_{i+1}|\\mathcal{F}_i]$.)\n",
    "\n",
    "\n",
    "+ Utiliser le processus $(Y^\\star_i)_{0\\le i \\le 2}$ pour montrer que $\\tau^\\star$ est un temps d'arrêt optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\blacktriangleright$ On remarquera que la construction de $\\tau^*$ ci-dessus nécessite de comparer la variable $(K - X_i)^+$ à la valeur courante de $Y_i = u_i(W_i)$.\n",
    "\n",
    "En remplaçant la vraie fonction $u_i$ par la fonction $\\tilde{u}_i$ estimée par régression empirique, on obtient l'estimateur\n",
    "\n",
    "$$\n",
    "\\check{u}_0^M = \\frac1{M} \\sum_{m = 1}^M (K - X^{m}_{\\tau_m})^+,\n",
    "\\qquad\n",
    "\\mbox{où }\n",
    "\\tau_m = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "0 & \\mbox{si } (K-x_0)^+ \\ge \\tilde u_0^M\n",
    "\\\\\n",
    "1 & \\mbox{si } (K-x_0)^+ < \\tilde u_0^M \\mbox{ et } (K-X_1^m)^+ \\ge \\tilde{u}_1(W_1^m)\n",
    "\\\\\n",
    "2 & \\mbox{sinon}.\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Compléter le calcul de cet estimateur dans le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prix Longstaff-Schwartz = 0.2491\n",
      "Time: 0.0045 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "### 4. Prix Longstaff-Schwartz\n",
    "#######################################\n",
    "time5 = time()\n",
    " \n",
    "def tempsArretOptimal(X1, approx_empirique_T1, K, x0, M):\n",
    "    ## On réutilise l'approximation empirique definie\n",
    "    ## plus haut, correspondant a v_1_tilde\n",
    "    gain_T1 = np.maximum(K - X1, 0.)\n",
    "    \n",
    "    u_1_tilde = np.maximum(gain_T1, approx_empirique_T1)\n",
    "     \n",
    "    mean_0 = np.mean(u_1_tilde)\n",
    "     \n",
    "    if np.maximum((K-x0), 0.) >= mean_0:\n",
    "        return np.zeros(M)\n",
    "    else:\n",
    "        tau = 1 * (u_1_tilde <= gain_T1) \\\n",
    "              + 2 * (u_1_tilde > gain_T1)\n",
    "     \n",
    "    return tau\n",
    " \n",
    "###################################################\n",
    "## To Do: completer avec le calcul\n",
    "## - du temps d'arret optimal tau (echantillon tau_m)\n",
    "## - de l'estimateur Longstaff-Schwartz du prix\n",
    "##\n",
    "tau = tempsArretOptimal(X1, v_1_tilde, K, x0, M)\n",
    "\n",
    "\n",
    "X_tau=(tau==0)*x0+(tau==1)*X1+(tau==2)*X2\n",
    "    \n",
    "    \n",
    "echantillon = np.maximum(K - X_tau,0)\n",
    "    \n",
    "estimateur_LongSchwartz = np.mean(echantillon)\n",
    "###################################################\n",
    " \n",
    "time6 = time()\n",
    " \n",
    "print(\"Prix Longstaff-Schwartz = %1.4f\" %estimateur_LongSchwartz)\n",
    "print(\"Time: %1.4f \\n\" %(time6 - time5 + time4 - time3 + timeSimulations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
